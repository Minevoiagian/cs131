{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "82bd2b57",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "82bd2b57"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "filePath = \"2019-04.csv\"\n",
        "#make the spark session and import the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "368ff544",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "368ff544"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"TestApp\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c8129594",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8129594",
        "outputId": "660b3ccf-4825-4def-f7b9-d36ccaf6b699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original top 5 rows\n",
            "+---------------+------------+------------+------------+\n",
            "|passenger_count|pulocationid|dolocationid|total_amount|\n",
            "+---------------+------------+------------+------------+\n",
            "|            1.0|       239.0|       239.0|         8.8|\n",
            "|            1.0|       230.0|       100.0|         8.3|\n",
            "|            1.0|        68.0|       127.0|       47.75|\n",
            "|            1.0|        68.0|        68.0|         7.3|\n",
            "|            1.0|        50.0|        42.0|       23.15|\n",
            "+---------------+------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#read the dataset, and then get the rows, debug as well to make sure things work\n",
        "taxiDF = spark.read.csv(filePath, header=True,inferSchema = True)\n",
        "print(\"Original top 5 rows\")\n",
        "taxiDF.select(\"passenger_count\",\"pulocationid\",\"dolocationid\",\"total_amount\").show(5)\n",
        "#split the dataset\n",
        "trainDF, testDF = taxiDF.randomSplit([0.8,0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9ffa6199",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9ffa6199"
      },
      "outputs": [],
      "source": [
        "#transformer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vecAssembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\",\"dolocationid\"], outputCol=\"features\")\n",
        "vecTrainDF = vecAssembler.transform(trainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4c7cf446",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "4c7cf446"
      },
      "outputs": [],
      "source": [
        "#make the decision tree model\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor(featuresCol=\"features\",labelCol=\"total_amount\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "42aa00d1",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "42aa00d1"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline (stages=[vecAssembler,dt])\n",
        "pipelineModel = pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "63fe2d15",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63fe2d15",
        "outputId": "850079e0-6f05-4bbf-8dbb-2c3f7f368efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 10 rows\n",
            "+---------------+------------+------------+------------------+\n",
            "|passenger_count|pulocationid|dolocationid|        prediction|\n",
            "+---------------+------------+------------+------------------+\n",
            "|            1.0|       246.0|        68.0| 16.94557683958677|\n",
            "|            1.0|       186.0|       261.0|23.242477286221444|\n",
            "|            3.0|       144.0|       170.0|16.748857527037178|\n",
            "|            1.0|       100.0|       170.0|17.810163163628932|\n",
            "|            1.0|       161.0|       107.0| 16.94557683958677|\n",
            "|            1.0|       239.0|        24.0|19.217579401582324|\n",
            "|            1.0|       148.0|         4.0|25.278734609579708|\n",
            "|            0.0|       186.0|        13.0|31.951581628420044|\n",
            "|            1.0|       249.0|       144.0|14.893731419692985|\n",
            "|            1.0|       249.0|        87.0| 16.94557683958677|\n",
            "+---------------+------------+------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#test dataset stuff\n",
        "predDF = pipelineModel.transform(testDF)\n",
        "print(\"Prediction 10 rows\")\n",
        "predDF.select(\"passenger_count\",\"pulocationid\",\"dolocationid\",\"prediction\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "11b6f1b3",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11b6f1b3",
        "outputId": "4d2d7151-caf5-4ec4-853e-52249c7ed275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  324.8517780082482\n"
          ]
        }
      ],
      "source": [
        "#check RMSE\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "regressionEvaluator = RegressionEvaluator(\n",
        "    predictionCol=\"prediction\",\n",
        "    labelCol=\"total_amount\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "rmse = regressionEvaluator.evaluate(predDF)\n",
        "print(\"RMSE: \",rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "998fabbe",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "998fabbe"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}